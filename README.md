---

# EcoTravel-GPT

EcoTravel-GPT is a Streamlit-based web application designed to help users **plan sustainable and efficient commutes**. The app leverages **retrieval-augmented generation (RAG)** with the Ollama Granite LLM to provide informative answers about eco-friendly transport options.

---

## Features

* Suggests **low-emission transport options** based on distance.
* Answers user queries about **green transport practices** using a **knowledge base**.
* Simple **RAG engine** to retrieve relevant context from text documents.
* Runs entirely **locally**, no cloud dependencies required (Ollama LLM server needed).

---

## Project Structure

```
D:\IBM Internship\Transport Planner\
│
├─ data/  
│   ├─ emissions_global.txt           # Global emission data for different transport modes  
│   ├─ sustainability_handbook.txt    # Sustainability best practices  
├─ kb/  
│   └─ transport_knowledge.txt        # Domain-specific transport knowledge base  
├─ app/
│   ├─ streamlit_app.py               # Main Streamlit app  
│   ├─ requirements.txt               # Necessary Python Modules
│
└─ README.md
```

> Files like `rag_test.py` and `calculator.py` are **optional** for testing and calculations. The **core app** is `eco_planner.py`.

---

## Setup Instructions

1. **Clone the repository**:

```bash
git clone <repo-url>
cd "D:\IBM Internship\Transport Planner\app"
```

2. **Create and activate a virtual environment**:

```bash
python -m venv ecoenv
.\ecoenv\Scripts\activate
```

3. **Install dependencies**:

```bash
pip install streamlit numpy langchain-ollama
```

> Ensure you have Ollama installed and running: [https://ollama.com](https://ollama.com)

4. **Start the Ollama LLM server**:

```bash
ollama serve
```

5. **Run the Streamlit app**:

```bash
streamlit run eco_planner.py
```

---

## Usage

1. Open the app in your browser (Streamlit will provide a local URL).
2. Select or enter your commute information.
3. Ask questions about green transport practices.
4. View **RAG-based answers** generated by the Granite model using your local knowledge base.

---

## Output/Project Screenshots

**Output #1:**
![Picture-1](Images/Long%20Distance.png)

**Output #2:**
![Picture-2](Images/Short%20Distance.png)

---

## Notes

* The RAG engine uses **simple in-memory embeddings** for demonstration. You can replace it with **sentence-transformers embeddings** for better accuracy.
* Ensure **Ollama server is running locally**; otherwise, the LLM will not respond.
* Text files in `data/` and `kb/` must exist for meaningful answers.

---

## Optional Enhancements

* Replace the numeric character embeddings with **real embeddings** for semantic search.
* Add **interactive distance selection and emissions calculation**.
* Integrate **Chroma** or **FAISS** if you want persistent vector storage.

---

## License

MIT License

---

